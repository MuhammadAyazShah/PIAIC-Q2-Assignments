{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSIGNMENT : IRIS MULTI-CLASS CLASSIFICATION\n",
    "\n",
    "###### Purpose :\n",
    "To predict the species of flower .\n",
    "###### Description :\n",
    "The dataset contains a set of 150 records under 5 attributes - Petal Length, Petal Width, Sepal Length, Sepal width and Class(Species).\n",
    "###### Requirements :\n",
    "1) Code must be in tf 2.0 .\n",
    "\n",
    "2) Accuracy must be in between 95-97% .\n",
    "\n",
    "3) Model shouldn't be Overfit (You can add drop out layer for this) ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1 : Load all the necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import models, layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2 : Data Preparation\n",
    "This step consists of multiple sub steps from data loading [download](https://github.com/ramsha275/PIAIC-Sir-Anees-Quarter-2/blob/master/Deep%20Learning/iris.csv),shuffling ,spliting in **Train** and **Test** sets to one-hot-enconding on labels . \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal.length  sepal.width  petal.length  petal.width    variety\n",
       "0             5.1          3.5           1.4          0.2     Setosa\n",
       "1             4.9          3.0           1.4          0.2     Setosa\n",
       "2             4.7          3.2           1.3          0.2     Setosa\n",
       "3             4.6          3.1           1.5          0.2     Setosa\n",
       "4             5.0          3.6           1.4          0.2     Setosa\n",
       "..            ...          ...           ...          ...        ...\n",
       "145           6.7          3.0           5.2          2.3  Virginica\n",
       "146           6.3          2.5           5.0          1.9  Virginica\n",
       "147           6.5          3.0           5.2          2.0  Virginica\n",
       "148           6.2          3.4           5.4          2.3  Virginica\n",
       "149           5.9          3.0           5.1          1.8  Virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('iris.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.asarray(data.iloc[:,:-1])\n",
    "y_data = np.asarray(data.iloc[:,-1])\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "one_hot = LabelBinarizer()\n",
    "y_data = one_hot.fit_transform(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(x_data, y_data,\n",
    "                                                                    test_size=0.2,\n",
    "                                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3 : Model Architecture \n",
    "\n",
    "\n",
    "###### Input : 4 \n",
    "###### 1 hidden Layer : 8 nodes\n",
    "###### Output : 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(8, activation = 'tanh', input_shape = (train_data.shape[1],)))\n",
    "model.add(layers.Dense(3, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 4 : Compilation Step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 5 : Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 108 samples, validate on 12 samples\n",
      "Epoch 1/240\n",
      "108/108 [==============================] - 1s 11ms/sample - loss: 0.9248 - accuracy: 0.7037 - val_loss: 1.0851 - val_accuracy: 0.4167\n",
      "Epoch 2/240\n",
      "108/108 [==============================] - 0s 778us/sample - loss: 0.8761 - accuracy: 0.7037 - val_loss: 1.0389 - val_accuracy: 0.4167\n",
      "Epoch 3/240\n",
      "108/108 [==============================] - 0s 612us/sample - loss: 0.8468 - accuracy: 0.7037 - val_loss: 0.9927 - val_accuracy: 0.4167\n",
      "Epoch 4/240\n",
      "108/108 [==============================] - 0s 751us/sample - loss: 0.8207 - accuracy: 0.7037 - val_loss: 0.9548 - val_accuracy: 0.4167\n",
      "Epoch 5/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.7999 - accuracy: 0.7037 - val_loss: 0.9266 - val_accuracy: 0.4167\n",
      "Epoch 6/240\n",
      "108/108 [==============================] - 0s 769us/sample - loss: 0.7814 - accuracy: 0.7037 - val_loss: 0.9025 - val_accuracy: 0.4167\n",
      "Epoch 7/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.7645 - accuracy: 0.7037 - val_loss: 0.8747 - val_accuracy: 0.4167\n",
      "Epoch 8/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.7466 - accuracy: 0.7037 - val_loss: 0.8466 - val_accuracy: 0.4167\n",
      "Epoch 9/240\n",
      "108/108 [==============================] - 0s 788us/sample - loss: 0.7302 - accuracy: 0.7037 - val_loss: 0.8230 - val_accuracy: 0.4167\n",
      "Epoch 10/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.7150 - accuracy: 0.7037 - val_loss: 0.7998 - val_accuracy: 0.4167\n",
      "Epoch 11/240\n",
      "108/108 [==============================] - 0s 658us/sample - loss: 0.7006 - accuracy: 0.7037 - val_loss: 0.7739 - val_accuracy: 0.4167\n",
      "Epoch 12/240\n",
      "108/108 [==============================] - 0s 760us/sample - loss: 0.6867 - accuracy: 0.7037 - val_loss: 0.7636 - val_accuracy: 0.4167\n",
      "Epoch 13/240\n",
      "108/108 [==============================] - 0s 751us/sample - loss: 0.6747 - accuracy: 0.7037 - val_loss: 0.7546 - val_accuracy: 0.4167\n",
      "Epoch 14/240\n",
      "108/108 [==============================] - 0s 760us/sample - loss: 0.6629 - accuracy: 0.7037 - val_loss: 0.7400 - val_accuracy: 0.4167\n",
      "Epoch 15/240\n",
      "108/108 [==============================] - 0s 788us/sample - loss: 0.6509 - accuracy: 0.7037 - val_loss: 0.7145 - val_accuracy: 0.4167\n",
      "Epoch 16/240\n",
      "108/108 [==============================] - 0s 630us/sample - loss: 0.6384 - accuracy: 0.7130 - val_loss: 0.6999 - val_accuracy: 0.4167\n",
      "Epoch 17/240\n",
      "108/108 [==============================] - 0s 760us/sample - loss: 0.6267 - accuracy: 0.7130 - val_loss: 0.6783 - val_accuracy: 0.4167\n",
      "Epoch 18/240\n",
      "108/108 [==============================] - 0s 630us/sample - loss: 0.6158 - accuracy: 0.7500 - val_loss: 0.6700 - val_accuracy: 0.4167\n",
      "Epoch 19/240\n",
      "108/108 [==============================] - 0s 751us/sample - loss: 0.6059 - accuracy: 0.7407 - val_loss: 0.6453 - val_accuracy: 0.5833\n",
      "Epoch 20/240\n",
      "108/108 [==============================] - 0s 778us/sample - loss: 0.5950 - accuracy: 0.8333 - val_loss: 0.6300 - val_accuracy: 0.5833\n",
      "Epoch 21/240\n",
      "108/108 [==============================] - 0s 686us/sample - loss: 0.5856 - accuracy: 0.8889 - val_loss: 0.6136 - val_accuracy: 0.6667\n",
      "Epoch 22/240\n",
      "108/108 [==============================] - 0s 778us/sample - loss: 0.5763 - accuracy: 0.8889 - val_loss: 0.5969 - val_accuracy: 0.8333\n",
      "Epoch 23/240\n",
      "108/108 [==============================] - 0s 769us/sample - loss: 0.5672 - accuracy: 0.9259 - val_loss: 0.5842 - val_accuracy: 0.8333\n",
      "Epoch 24/240\n",
      "108/108 [==============================] - 0s 927us/sample - loss: 0.5584 - accuracy: 0.9167 - val_loss: 0.5726 - val_accuracy: 0.8333\n",
      "Epoch 25/240\n",
      "108/108 [==============================] - 0s 639us/sample - loss: 0.5500 - accuracy: 0.9167 - val_loss: 0.5621 - val_accuracy: 0.8333\n",
      "Epoch 26/240\n",
      "108/108 [==============================] - 0s 908us/sample - loss: 0.5412 - accuracy: 0.9167 - val_loss: 0.5512 - val_accuracy: 0.9167\n",
      "Epoch 27/240\n",
      "108/108 [==============================] - 0s 621us/sample - loss: 0.5325 - accuracy: 0.9259 - val_loss: 0.5523 - val_accuracy: 0.8333\n",
      "Epoch 28/240\n",
      "108/108 [==============================] - 0s 751us/sample - loss: 0.5247 - accuracy: 0.9259 - val_loss: 0.5343 - val_accuracy: 0.9167\n",
      "Epoch 29/240\n",
      "108/108 [==============================] - 0s 621us/sample - loss: 0.5166 - accuracy: 0.9259 - val_loss: 0.5346 - val_accuracy: 0.9167\n",
      "Epoch 30/240\n",
      "108/108 [==============================] - 0s 760us/sample - loss: 0.5097 - accuracy: 0.9352 - val_loss: 0.5292 - val_accuracy: 0.9167\n",
      "Epoch 31/240\n",
      "108/108 [==============================] - 0s 630us/sample - loss: 0.5023 - accuracy: 0.9259 - val_loss: 0.5175 - val_accuracy: 0.9167\n",
      "Epoch 32/240\n",
      "108/108 [==============================] - 0s 621us/sample - loss: 0.4965 - accuracy: 0.9259 - val_loss: 0.5161 - val_accuracy: 0.9167\n",
      "Epoch 33/240\n",
      "108/108 [==============================] - 0s 621us/sample - loss: 0.4885 - accuracy: 0.9352 - val_loss: 0.5114 - val_accuracy: 0.9167\n",
      "Epoch 34/240\n",
      "108/108 [==============================] - 0s 751us/sample - loss: 0.4827 - accuracy: 0.9352 - val_loss: 0.4957 - val_accuracy: 0.9167\n",
      "Epoch 35/240\n",
      "108/108 [==============================] - 0s 621us/sample - loss: 0.4776 - accuracy: 0.9352 - val_loss: 0.4877 - val_accuracy: 0.9167\n",
      "Epoch 36/240\n",
      "108/108 [==============================] - 0s 677us/sample - loss: 0.4710 - accuracy: 0.9537 - val_loss: 0.4743 - val_accuracy: 0.9167\n",
      "Epoch 37/240\n",
      "108/108 [==============================] - 0s 630us/sample - loss: 0.4655 - accuracy: 0.9444 - val_loss: 0.4672 - val_accuracy: 0.9167\n",
      "Epoch 38/240\n",
      "108/108 [==============================] - 0s 612us/sample - loss: 0.4593 - accuracy: 0.9444 - val_loss: 0.4693 - val_accuracy: 0.9167\n",
      "Epoch 39/240\n",
      "108/108 [==============================] - 0s 593us/sample - loss: 0.4552 - accuracy: 0.9537 - val_loss: 0.4609 - val_accuracy: 0.9167\n",
      "Epoch 40/240\n",
      "108/108 [==============================] - 0s 612us/sample - loss: 0.4491 - accuracy: 0.9537 - val_loss: 0.4641 - val_accuracy: 0.9167\n",
      "Epoch 41/240\n",
      "108/108 [==============================] - 0s 593us/sample - loss: 0.4442 - accuracy: 0.9537 - val_loss: 0.4614 - val_accuracy: 0.9167\n",
      "Epoch 42/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.4399 - accuracy: 0.9444 - val_loss: 0.4603 - val_accuracy: 0.9167\n",
      "Epoch 43/240\n",
      "108/108 [==============================] - 0s 593us/sample - loss: 0.4350 - accuracy: 0.9444 - val_loss: 0.4515 - val_accuracy: 0.9167\n",
      "Epoch 44/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.4302 - accuracy: 0.9630 - val_loss: 0.4414 - val_accuracy: 0.9167\n",
      "Epoch 45/240\n",
      "108/108 [==============================] - 0s 584us/sample - loss: 0.4258 - accuracy: 0.9537 - val_loss: 0.4340 - val_accuracy: 0.9167\n",
      "Epoch 46/240\n",
      "108/108 [==============================] - 0s 714us/sample - loss: 0.4240 - accuracy: 0.9537 - val_loss: 0.4364 - val_accuracy: 0.9167\n",
      "Epoch 47/240\n",
      "108/108 [==============================] - 0s 704us/sample - loss: 0.4184 - accuracy: 0.9352 - val_loss: 0.4232 - val_accuracy: 0.9167\n",
      "Epoch 48/240\n",
      "108/108 [==============================] - 0s 612us/sample - loss: 0.4151 - accuracy: 0.9537 - val_loss: 0.4144 - val_accuracy: 0.9167\n",
      "Epoch 49/240\n",
      "108/108 [==============================] - 0s 612us/sample - loss: 0.4110 - accuracy: 0.9630 - val_loss: 0.4128 - val_accuracy: 0.9167\n",
      "Epoch 50/240\n",
      "108/108 [==============================] - 0s 612us/sample - loss: 0.4082 - accuracy: 0.9630 - val_loss: 0.4095 - val_accuracy: 0.9167\n",
      "Epoch 51/240\n",
      "108/108 [==============================] - 0s 639us/sample - loss: 0.4042 - accuracy: 0.9537 - val_loss: 0.4201 - val_accuracy: 0.9167\n",
      "Epoch 52/240\n",
      "108/108 [==============================] - 0s 741us/sample - loss: 0.4034 - accuracy: 0.9352 - val_loss: 0.4002 - val_accuracy: 1.0000\n",
      "Epoch 53/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.3986 - accuracy: 0.9537 - val_loss: 0.3995 - val_accuracy: 0.9167\n",
      "Epoch 54/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.3961 - accuracy: 0.9630 - val_loss: 0.3971 - val_accuracy: 0.9167\n",
      "Epoch 55/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.3936 - accuracy: 0.9630 - val_loss: 0.3962 - val_accuracy: 0.9167\n",
      "Epoch 56/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 0s 723us/sample - loss: 0.3904 - accuracy: 0.9630 - val_loss: 0.3988 - val_accuracy: 0.9167\n",
      "Epoch 57/240\n",
      "108/108 [==============================] - 0s 658us/sample - loss: 0.3885 - accuracy: 0.9537 - val_loss: 0.4008 - val_accuracy: 0.9167\n",
      "Epoch 58/240\n",
      "108/108 [==============================] - 0s 538us/sample - loss: 0.3850 - accuracy: 0.9444 - val_loss: 0.3884 - val_accuracy: 0.9167\n",
      "Epoch 59/240\n",
      "108/108 [==============================] - 0s 528us/sample - loss: 0.3838 - accuracy: 0.9630 - val_loss: 0.3765 - val_accuracy: 1.0000\n",
      "Epoch 60/240\n",
      "108/108 [==============================] - 0s 565us/sample - loss: 0.3806 - accuracy: 0.9537 - val_loss: 0.3729 - val_accuracy: 1.0000\n",
      "Epoch 61/240\n",
      "108/108 [==============================] - 0s 593us/sample - loss: 0.3778 - accuracy: 0.9630 - val_loss: 0.3774 - val_accuracy: 1.0000\n",
      "Epoch 62/240\n",
      "108/108 [==============================] - 0s 565us/sample - loss: 0.3746 - accuracy: 0.9630 - val_loss: 0.3767 - val_accuracy: 1.0000\n",
      "Epoch 63/240\n",
      "108/108 [==============================] - 0s 538us/sample - loss: 0.3726 - accuracy: 0.9630 - val_loss: 0.3799 - val_accuracy: 0.9167\n",
      "Epoch 64/240\n",
      "108/108 [==============================] - 0s 565us/sample - loss: 0.3701 - accuracy: 0.9537 - val_loss: 0.3650 - val_accuracy: 1.0000\n",
      "Epoch 65/240\n",
      "108/108 [==============================] - 0s 547us/sample - loss: 0.3697 - accuracy: 0.9630 - val_loss: 0.3630 - val_accuracy: 1.0000\n",
      "Epoch 66/240\n",
      "108/108 [==============================] - 0s 547us/sample - loss: 0.3665 - accuracy: 0.9722 - val_loss: 0.3674 - val_accuracy: 1.0000\n",
      "Epoch 67/240\n",
      "108/108 [==============================] - 0s 584us/sample - loss: 0.3624 - accuracy: 0.9630 - val_loss: 0.3646 - val_accuracy: 1.0000\n",
      "Epoch 68/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.3603 - accuracy: 0.9630 - val_loss: 0.3718 - val_accuracy: 0.9167\n",
      "Epoch 69/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.3587 - accuracy: 0.9630 - val_loss: 0.3641 - val_accuracy: 0.9167\n",
      "Epoch 70/240\n",
      "108/108 [==============================] - 0s 593us/sample - loss: 0.3565 - accuracy: 0.9352 - val_loss: 0.3448 - val_accuracy: 1.0000\n",
      "Epoch 71/240\n",
      "108/108 [==============================] - 0s 584us/sample - loss: 0.3568 - accuracy: 0.9630 - val_loss: 0.3368 - val_accuracy: 1.0000\n",
      "Epoch 72/240\n",
      "108/108 [==============================] - 0s 584us/sample - loss: 0.3539 - accuracy: 0.9722 - val_loss: 0.3390 - val_accuracy: 1.0000\n",
      "Epoch 73/240\n",
      "108/108 [==============================] - 0s 621us/sample - loss: 0.3504 - accuracy: 0.9630 - val_loss: 0.3422 - val_accuracy: 1.0000\n",
      "Epoch 74/240\n",
      "108/108 [==============================] - 0s 538us/sample - loss: 0.3485 - accuracy: 0.9630 - val_loss: 0.3418 - val_accuracy: 1.0000\n",
      "Epoch 75/240\n",
      "108/108 [==============================] - 0s 584us/sample - loss: 0.3474 - accuracy: 0.9537 - val_loss: 0.3279 - val_accuracy: 1.0000\n",
      "Epoch 76/240\n",
      "108/108 [==============================] - 0s 547us/sample - loss: 0.3446 - accuracy: 0.9630 - val_loss: 0.3396 - val_accuracy: 1.0000\n",
      "Epoch 77/240\n",
      "108/108 [==============================] - 0s 593us/sample - loss: 0.3429 - accuracy: 0.9630 - val_loss: 0.3357 - val_accuracy: 1.0000\n",
      "Epoch 78/240\n",
      "108/108 [==============================] - 0s 593us/sample - loss: 0.3411 - accuracy: 0.9630 - val_loss: 0.3451 - val_accuracy: 1.0000\n",
      "Epoch 79/240\n",
      "108/108 [==============================] - 0s 593us/sample - loss: 0.3392 - accuracy: 0.9630 - val_loss: 0.3277 - val_accuracy: 1.0000\n",
      "Epoch 80/240\n",
      "108/108 [==============================] - 0s 538us/sample - loss: 0.3395 - accuracy: 0.9630 - val_loss: 0.3227 - val_accuracy: 1.0000\n",
      "Epoch 81/240\n",
      "108/108 [==============================] - 0s 584us/sample - loss: 0.3356 - accuracy: 0.9630 - val_loss: 0.3157 - val_accuracy: 1.0000\n",
      "Epoch 82/240\n",
      "108/108 [==============================] - 0s 556us/sample - loss: 0.3355 - accuracy: 0.9537 - val_loss: 0.3154 - val_accuracy: 1.0000\n",
      "Epoch 83/240\n",
      "108/108 [==============================] - 0s 538us/sample - loss: 0.3332 - accuracy: 0.9722 - val_loss: 0.3180 - val_accuracy: 1.0000\n",
      "Epoch 84/240\n",
      "108/108 [==============================] - 0s 612us/sample - loss: 0.3301 - accuracy: 0.9630 - val_loss: 0.3127 - val_accuracy: 1.0000\n",
      "Epoch 85/240\n",
      "108/108 [==============================] - 0s 547us/sample - loss: 0.3300 - accuracy: 0.9630 - val_loss: 0.3070 - val_accuracy: 1.0000\n",
      "Epoch 86/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.3283 - accuracy: 0.9630 - val_loss: 0.2986 - val_accuracy: 1.0000\n",
      "Epoch 87/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.3259 - accuracy: 0.9722 - val_loss: 0.3049 - val_accuracy: 1.0000\n",
      "Epoch 88/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.3249 - accuracy: 0.9537 - val_loss: 0.3151 - val_accuracy: 1.0000\n",
      "Epoch 89/240\n",
      "108/108 [==============================] - 0s 612us/sample - loss: 0.3217 - accuracy: 0.9630 - val_loss: 0.3092 - val_accuracy: 1.0000\n",
      "Epoch 90/240\n",
      "108/108 [==============================] - 0s 584us/sample - loss: 0.3203 - accuracy: 0.9630 - val_loss: 0.3154 - val_accuracy: 1.0000\n",
      "Epoch 91/240\n",
      "108/108 [==============================] - 0s 612us/sample - loss: 0.3188 - accuracy: 0.9630 - val_loss: 0.3128 - val_accuracy: 1.0000\n",
      "Epoch 92/240\n",
      "108/108 [==============================] - 0s 612us/sample - loss: 0.3164 - accuracy: 0.9630 - val_loss: 0.2993 - val_accuracy: 1.0000\n",
      "Epoch 93/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.3187 - accuracy: 0.9630 - val_loss: 0.3129 - val_accuracy: 1.0000\n",
      "Epoch 94/240\n",
      "108/108 [==============================] - 0s 612us/sample - loss: 0.3143 - accuracy: 0.9630 - val_loss: 0.3131 - val_accuracy: 1.0000\n",
      "Epoch 95/240\n",
      "108/108 [==============================] - 0s 612us/sample - loss: 0.3134 - accuracy: 0.9630 - val_loss: 0.2956 - val_accuracy: 1.0000\n",
      "Epoch 96/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.3103 - accuracy: 0.9630 - val_loss: 0.2933 - val_accuracy: 1.0000\n",
      "Epoch 97/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.3094 - accuracy: 0.9630 - val_loss: 0.2854 - val_accuracy: 1.0000\n",
      "Epoch 98/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.3078 - accuracy: 0.9722 - val_loss: 0.2867 - val_accuracy: 1.0000\n",
      "Epoch 99/240\n",
      "108/108 [==============================] - 0s 639us/sample - loss: 0.3067 - accuracy: 0.9722 - val_loss: 0.2868 - val_accuracy: 1.0000\n",
      "Epoch 100/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.3043 - accuracy: 0.9630 - val_loss: 0.2868 - val_accuracy: 1.0000\n",
      "Epoch 101/240\n",
      "108/108 [==============================] - 0s 556us/sample - loss: 0.3050 - accuracy: 0.9630 - val_loss: 0.2826 - val_accuracy: 1.0000\n",
      "Epoch 102/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.3029 - accuracy: 0.9722 - val_loss: 0.2877 - val_accuracy: 1.0000\n",
      "Epoch 103/240\n",
      "108/108 [==============================] - 0s 528us/sample - loss: 0.3024 - accuracy: 0.9630 - val_loss: 0.2855 - val_accuracy: 1.0000\n",
      "Epoch 104/240\n",
      "108/108 [==============================] - 0s 547us/sample - loss: 0.2983 - accuracy: 0.9630 - val_loss: 0.2950 - val_accuracy: 1.0000\n",
      "Epoch 105/240\n",
      "108/108 [==============================] - 0s 612us/sample - loss: 0.2971 - accuracy: 0.9630 - val_loss: 0.2907 - val_accuracy: 1.0000\n",
      "Epoch 106/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.2959 - accuracy: 0.9630 - val_loss: 0.2728 - val_accuracy: 1.0000\n",
      "Epoch 107/240\n",
      "108/108 [==============================] - 0s 612us/sample - loss: 0.2941 - accuracy: 0.9630 - val_loss: 0.2836 - val_accuracy: 1.0000\n",
      "Epoch 108/240\n",
      "108/108 [==============================] - 0s 528us/sample - loss: 0.2927 - accuracy: 0.9630 - val_loss: 0.2916 - val_accuracy: 1.0000\n",
      "Epoch 109/240\n",
      "108/108 [==============================] - 0s 584us/sample - loss: 0.2917 - accuracy: 0.9630 - val_loss: 0.2715 - val_accuracy: 1.0000\n",
      "Epoch 110/240\n",
      "108/108 [==============================] - 0s 556us/sample - loss: 0.2897 - accuracy: 0.9630 - val_loss: 0.2606 - val_accuracy: 1.0000\n",
      "Epoch 111/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 0s 547us/sample - loss: 0.2885 - accuracy: 0.9722 - val_loss: 0.2656 - val_accuracy: 1.0000\n",
      "Epoch 112/240\n",
      "108/108 [==============================] - 0s 565us/sample - loss: 0.2880 - accuracy: 0.9630 - val_loss: 0.2631 - val_accuracy: 1.0000\n",
      "Epoch 113/240\n",
      "108/108 [==============================] - 0s 584us/sample - loss: 0.2855 - accuracy: 0.9630 - val_loss: 0.2690 - val_accuracy: 1.0000\n",
      "Epoch 114/240\n",
      "108/108 [==============================] - 0s 575us/sample - loss: 0.2860 - accuracy: 0.9630 - val_loss: 0.2785 - val_accuracy: 1.0000\n",
      "Epoch 115/240\n",
      "108/108 [==============================] - 0s 612us/sample - loss: 0.2838 - accuracy: 0.9630 - val_loss: 0.2690 - val_accuracy: 1.0000\n",
      "Epoch 116/240\n",
      "108/108 [==============================] - 0s 575us/sample - loss: 0.2827 - accuracy: 0.9630 - val_loss: 0.2705 - val_accuracy: 1.0000\n",
      "Epoch 117/240\n",
      "108/108 [==============================] - 0s 528us/sample - loss: 0.2803 - accuracy: 0.9630 - val_loss: 0.2742 - val_accuracy: 1.0000\n",
      "Epoch 118/240\n",
      "108/108 [==============================] - 0s 575us/sample - loss: 0.2818 - accuracy: 0.9537 - val_loss: 0.2563 - val_accuracy: 1.0000\n",
      "Epoch 119/240\n",
      "108/108 [==============================] - 0s 584us/sample - loss: 0.2780 - accuracy: 0.9630 - val_loss: 0.2509 - val_accuracy: 1.0000\n",
      "Epoch 120/240\n",
      "108/108 [==============================] - 0s 593us/sample - loss: 0.2768 - accuracy: 0.9722 - val_loss: 0.2612 - val_accuracy: 1.0000\n",
      "Epoch 121/240\n",
      "108/108 [==============================] - 0s 584us/sample - loss: 0.2747 - accuracy: 0.9630 - val_loss: 0.2497 - val_accuracy: 1.0000\n",
      "Epoch 122/240\n",
      "108/108 [==============================] - 0s 538us/sample - loss: 0.2732 - accuracy: 0.9630 - val_loss: 0.2485 - val_accuracy: 1.0000\n",
      "Epoch 123/240\n",
      "108/108 [==============================] - 0s 584us/sample - loss: 0.2744 - accuracy: 0.9630 - val_loss: 0.2525 - val_accuracy: 1.0000\n",
      "Epoch 124/240\n",
      "108/108 [==============================] - 0s 658us/sample - loss: 0.2708 - accuracy: 0.9630 - val_loss: 0.2577 - val_accuracy: 1.0000\n",
      "Epoch 125/240\n",
      "108/108 [==============================] - 0s 528us/sample - loss: 0.2699 - accuracy: 0.9630 - val_loss: 0.2505 - val_accuracy: 1.0000\n",
      "Epoch 126/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.2678 - accuracy: 0.9630 - val_loss: 0.2518 - val_accuracy: 1.0000\n",
      "Epoch 127/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.2670 - accuracy: 0.9630 - val_loss: 0.2589 - val_accuracy: 1.0000\n",
      "Epoch 128/240\n",
      "108/108 [==============================] - 0s 593us/sample - loss: 0.2667 - accuracy: 0.9537 - val_loss: 0.2408 - val_accuracy: 1.0000\n",
      "Epoch 129/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.2635 - accuracy: 0.9722 - val_loss: 0.2382 - val_accuracy: 1.0000\n",
      "Epoch 130/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.2638 - accuracy: 0.9630 - val_loss: 0.2353 - val_accuracy: 1.0000\n",
      "Epoch 131/240\n",
      "108/108 [==============================] - 0s 612us/sample - loss: 0.2621 - accuracy: 0.9630 - val_loss: 0.2268 - val_accuracy: 1.0000\n",
      "Epoch 132/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.2594 - accuracy: 0.9722 - val_loss: 0.2388 - val_accuracy: 1.0000\n",
      "Epoch 133/240\n",
      "108/108 [==============================] - 0s 528us/sample - loss: 0.2588 - accuracy: 0.9722 - val_loss: 0.2384 - val_accuracy: 1.0000\n",
      "Epoch 134/240\n",
      "108/108 [==============================] - 0s 565us/sample - loss: 0.2586 - accuracy: 0.9630 - val_loss: 0.2253 - val_accuracy: 1.0000\n",
      "Epoch 135/240\n",
      "108/108 [==============================] - 0s 556us/sample - loss: 0.2557 - accuracy: 0.9722 - val_loss: 0.2279 - val_accuracy: 1.0000\n",
      "Epoch 136/240\n",
      "108/108 [==============================] - 0s 556us/sample - loss: 0.2574 - accuracy: 0.9630 - val_loss: 0.2230 - val_accuracy: 1.0000\n",
      "Epoch 137/240\n",
      "108/108 [==============================] - 0s 584us/sample - loss: 0.2534 - accuracy: 0.9722 - val_loss: 0.2269 - val_accuracy: 1.0000\n",
      "Epoch 138/240\n",
      "108/108 [==============================] - 0s 556us/sample - loss: 0.2530 - accuracy: 0.9630 - val_loss: 0.2329 - val_accuracy: 1.0000\n",
      "Epoch 139/240\n",
      "108/108 [==============================] - 0s 593us/sample - loss: 0.2510 - accuracy: 0.9630 - val_loss: 0.2296 - val_accuracy: 1.0000\n",
      "Epoch 140/240\n",
      "108/108 [==============================] - 0s 593us/sample - loss: 0.2503 - accuracy: 0.9630 - val_loss: 0.2329 - val_accuracy: 1.0000\n",
      "Epoch 141/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.2488 - accuracy: 0.9630 - val_loss: 0.2200 - val_accuracy: 1.0000\n",
      "Epoch 142/240\n",
      "108/108 [==============================] - 0s 593us/sample - loss: 0.2465 - accuracy: 0.9630 - val_loss: 0.2135 - val_accuracy: 1.0000\n",
      "Epoch 143/240\n",
      "108/108 [==============================] - 0s 612us/sample - loss: 0.2464 - accuracy: 0.9815 - val_loss: 0.2256 - val_accuracy: 1.0000\n",
      "Epoch 144/240\n",
      "108/108 [==============================] - 0s 612us/sample - loss: 0.2466 - accuracy: 0.9630 - val_loss: 0.2201 - val_accuracy: 1.0000\n",
      "Epoch 145/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.2429 - accuracy: 0.9630 - val_loss: 0.2116 - val_accuracy: 1.0000\n",
      "Epoch 146/240\n",
      "108/108 [==============================] - 0s 593us/sample - loss: 0.2426 - accuracy: 0.9722 - val_loss: 0.2070 - val_accuracy: 1.0000\n",
      "Epoch 147/240\n",
      "108/108 [==============================] - 0s 565us/sample - loss: 0.2419 - accuracy: 0.9722 - val_loss: 0.2005 - val_accuracy: 1.0000\n",
      "Epoch 148/240\n",
      "108/108 [==============================] - 0s 538us/sample - loss: 0.2394 - accuracy: 0.9815 - val_loss: 0.2031 - val_accuracy: 1.0000\n",
      "Epoch 149/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.2385 - accuracy: 0.9722 - val_loss: 0.1984 - val_accuracy: 1.0000\n",
      "Epoch 150/240\n",
      "108/108 [==============================] - 0s 547us/sample - loss: 0.2375 - accuracy: 0.9722 - val_loss: 0.1979 - val_accuracy: 1.0000\n",
      "Epoch 151/240\n",
      "108/108 [==============================] - 0s 538us/sample - loss: 0.2365 - accuracy: 0.9722 - val_loss: 0.1997 - val_accuracy: 1.0000\n",
      "Epoch 152/240\n",
      "108/108 [==============================] - 0s 547us/sample - loss: 0.2347 - accuracy: 0.9630 - val_loss: 0.1881 - val_accuracy: 1.0000\n",
      "Epoch 153/240\n",
      "108/108 [==============================] - 0s 575us/sample - loss: 0.2364 - accuracy: 0.9815 - val_loss: 0.1889 - val_accuracy: 1.0000\n",
      "Epoch 154/240\n",
      "108/108 [==============================] - 0s 649us/sample - loss: 0.2329 - accuracy: 0.9815 - val_loss: 0.1896 - val_accuracy: 1.0000\n",
      "Epoch 155/240\n",
      "108/108 [==============================] - 0s 547us/sample - loss: 0.2309 - accuracy: 0.9722 - val_loss: 0.1894 - val_accuracy: 1.0000\n",
      "Epoch 156/240\n",
      "108/108 [==============================] - 0s 538us/sample - loss: 0.2302 - accuracy: 0.9722 - val_loss: 0.1815 - val_accuracy: 1.0000\n",
      "Epoch 157/240\n",
      "108/108 [==============================] - 0s 556us/sample - loss: 0.2300 - accuracy: 0.9815 - val_loss: 0.1811 - val_accuracy: 1.0000\n",
      "Epoch 158/240\n",
      "108/108 [==============================] - 0s 621us/sample - loss: 0.2280 - accuracy: 0.9722 - val_loss: 0.1860 - val_accuracy: 1.0000\n",
      "Epoch 159/240\n",
      "108/108 [==============================] - 0s 556us/sample - loss: 0.2256 - accuracy: 0.9722 - val_loss: 0.1952 - val_accuracy: 1.0000\n",
      "Epoch 160/240\n",
      "108/108 [==============================] - 0s 556us/sample - loss: 0.2267 - accuracy: 0.9630 - val_loss: 0.1825 - val_accuracy: 1.0000\n",
      "Epoch 161/240\n",
      "108/108 [==============================] - 0s 556us/sample - loss: 0.2234 - accuracy: 0.9722 - val_loss: 0.1828 - val_accuracy: 1.0000\n",
      "Epoch 162/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.2247 - accuracy: 0.9815 - val_loss: 0.1839 - val_accuracy: 1.0000\n",
      "Epoch 163/240\n",
      "108/108 [==============================] - 0s 630us/sample - loss: 0.2213 - accuracy: 0.9722 - val_loss: 0.1891 - val_accuracy: 1.0000\n",
      "Epoch 164/240\n",
      "108/108 [==============================] - 0s 556us/sample - loss: 0.2194 - accuracy: 0.9630 - val_loss: 0.1860 - val_accuracy: 1.0000\n",
      "Epoch 165/240\n",
      "108/108 [==============================] - 0s 528us/sample - loss: 0.2216 - accuracy: 0.9630 - val_loss: 0.1888 - val_accuracy: 1.0000\n",
      "Epoch 166/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 0s 556us/sample - loss: 0.2191 - accuracy: 0.9630 - val_loss: 0.1820 - val_accuracy: 1.0000\n",
      "Epoch 167/240\n",
      "108/108 [==============================] - 0s 593us/sample - loss: 0.2161 - accuracy: 0.9630 - val_loss: 0.1824 - val_accuracy: 1.0000\n",
      "Epoch 168/240\n",
      "108/108 [==============================] - 0s 538us/sample - loss: 0.2168 - accuracy: 0.9630 - val_loss: 0.1769 - val_accuracy: 1.0000\n",
      "Epoch 169/240\n",
      "108/108 [==============================] - 0s 528us/sample - loss: 0.2141 - accuracy: 0.9722 - val_loss: 0.1866 - val_accuracy: 1.0000\n",
      "Epoch 170/240\n",
      "108/108 [==============================] - 0s 547us/sample - loss: 0.2152 - accuracy: 0.9630 - val_loss: 0.1882 - val_accuracy: 1.0000\n",
      "Epoch 171/240\n",
      "108/108 [==============================] - 0s 584us/sample - loss: 0.2126 - accuracy: 0.9630 - val_loss: 0.1829 - val_accuracy: 1.0000\n",
      "Epoch 172/240\n",
      "108/108 [==============================] - 0s 528us/sample - loss: 0.2110 - accuracy: 0.9630 - val_loss: 0.1693 - val_accuracy: 1.0000\n",
      "Epoch 173/240\n",
      "108/108 [==============================] - 0s 593us/sample - loss: 0.2111 - accuracy: 0.9722 - val_loss: 0.1720 - val_accuracy: 1.0000\n",
      "Epoch 174/240\n",
      "108/108 [==============================] - 0s 556us/sample - loss: 0.2088 - accuracy: 0.9722 - val_loss: 0.1678 - val_accuracy: 1.0000\n",
      "Epoch 175/240\n",
      "108/108 [==============================] - 0s 593us/sample - loss: 0.2077 - accuracy: 0.9722 - val_loss: 0.1655 - val_accuracy: 1.0000\n",
      "Epoch 176/240\n",
      "108/108 [==============================] - 0s 584us/sample - loss: 0.2063 - accuracy: 0.9722 - val_loss: 0.1708 - val_accuracy: 1.0000\n",
      "Epoch 177/240\n",
      "108/108 [==============================] - 0s 593us/sample - loss: 0.2050 - accuracy: 0.9630 - val_loss: 0.1600 - val_accuracy: 1.0000\n",
      "Epoch 178/240\n",
      "108/108 [==============================] - 0s 538us/sample - loss: 0.2042 - accuracy: 0.9722 - val_loss: 0.1671 - val_accuracy: 1.0000\n",
      "Epoch 179/240\n",
      "108/108 [==============================] - 0s 584us/sample - loss: 0.2053 - accuracy: 0.9630 - val_loss: 0.1750 - val_accuracy: 1.0000\n",
      "Epoch 180/240\n",
      "108/108 [==============================] - 0s 584us/sample - loss: 0.2039 - accuracy: 0.9630 - val_loss: 0.1720 - val_accuracy: 1.0000\n",
      "Epoch 181/240\n",
      "108/108 [==============================] - 0s 565us/sample - loss: 0.2020 - accuracy: 0.9630 - val_loss: 0.1546 - val_accuracy: 1.0000\n",
      "Epoch 182/240\n",
      "108/108 [==============================] - 0s 593us/sample - loss: 0.2003 - accuracy: 0.9815 - val_loss: 0.1503 - val_accuracy: 1.0000\n",
      "Epoch 183/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.1995 - accuracy: 0.9815 - val_loss: 0.1536 - val_accuracy: 1.0000\n",
      "Epoch 184/240\n",
      "108/108 [==============================] - 0s 538us/sample - loss: 0.1972 - accuracy: 0.9815 - val_loss: 0.1579 - val_accuracy: 1.0000\n",
      "Epoch 185/240\n",
      "108/108 [==============================] - 0s 584us/sample - loss: 0.1971 - accuracy: 0.9722 - val_loss: 0.1564 - val_accuracy: 1.0000\n",
      "Epoch 186/240\n",
      "108/108 [==============================] - 0s 565us/sample - loss: 0.1959 - accuracy: 0.9722 - val_loss: 0.1630 - val_accuracy: 1.0000\n",
      "Epoch 187/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.1950 - accuracy: 0.9630 - val_loss: 0.1625 - val_accuracy: 1.0000\n",
      "Epoch 188/240\n",
      "108/108 [==============================] - 0s 584us/sample - loss: 0.1935 - accuracy: 0.9630 - val_loss: 0.1560 - val_accuracy: 1.0000\n",
      "Epoch 189/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.1921 - accuracy: 0.9630 - val_loss: 0.1413 - val_accuracy: 1.0000\n",
      "Epoch 190/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.1908 - accuracy: 0.9815 - val_loss: 0.1518 - val_accuracy: 1.0000\n",
      "Epoch 191/240\n",
      "108/108 [==============================] - 0s 538us/sample - loss: 0.1897 - accuracy: 0.9722 - val_loss: 0.1540 - val_accuracy: 1.0000\n",
      "Epoch 192/240\n",
      "108/108 [==============================] - 0s 575us/sample - loss: 0.1889 - accuracy: 0.9630 - val_loss: 0.1407 - val_accuracy: 1.0000\n",
      "Epoch 193/240\n",
      "108/108 [==============================] - 0s 547us/sample - loss: 0.1892 - accuracy: 0.9722 - val_loss: 0.1436 - val_accuracy: 1.0000\n",
      "Epoch 194/240\n",
      "108/108 [==============================] - 0s 538us/sample - loss: 0.1862 - accuracy: 0.9722 - val_loss: 0.1364 - val_accuracy: 1.0000\n",
      "Epoch 195/240\n",
      "108/108 [==============================] - 0s 630us/sample - loss: 0.1859 - accuracy: 0.9722 - val_loss: 0.1393 - val_accuracy: 1.0000\n",
      "Epoch 196/240\n",
      "108/108 [==============================] - 0s 538us/sample - loss: 0.1838 - accuracy: 0.9722 - val_loss: 0.1361 - val_accuracy: 1.0000\n",
      "Epoch 197/240\n",
      "108/108 [==============================] - 0s 575us/sample - loss: 0.1838 - accuracy: 0.9815 - val_loss: 0.1313 - val_accuracy: 1.0000\n",
      "Epoch 198/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.1827 - accuracy: 0.9815 - val_loss: 0.1346 - val_accuracy: 1.0000\n",
      "Epoch 199/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.1827 - accuracy: 0.9722 - val_loss: 0.1421 - val_accuracy: 1.0000\n",
      "Epoch 200/240\n",
      "108/108 [==============================] - 0s 612us/sample - loss: 0.1820 - accuracy: 0.9722 - val_loss: 0.1453 - val_accuracy: 1.0000\n",
      "Epoch 201/240\n",
      "108/108 [==============================] - 0s 593us/sample - loss: 0.1794 - accuracy: 0.9630 - val_loss: 0.1371 - val_accuracy: 1.0000\n",
      "Epoch 202/240\n",
      "108/108 [==============================] - 0s 612us/sample - loss: 0.1775 - accuracy: 0.9722 - val_loss: 0.1367 - val_accuracy: 1.0000\n",
      "Epoch 203/240\n",
      "108/108 [==============================] - 0s 612us/sample - loss: 0.1769 - accuracy: 0.9722 - val_loss: 0.1356 - val_accuracy: 1.0000\n",
      "Epoch 204/240\n",
      "108/108 [==============================] - 0s 612us/sample - loss: 0.1768 - accuracy: 0.9630 - val_loss: 0.1204 - val_accuracy: 1.0000\n",
      "Epoch 205/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.1753 - accuracy: 0.9815 - val_loss: 0.1224 - val_accuracy: 1.0000\n",
      "Epoch 206/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.1742 - accuracy: 0.9815 - val_loss: 0.1260 - val_accuracy: 1.0000\n",
      "Epoch 207/240\n",
      "108/108 [==============================] - 0s 612us/sample - loss: 0.1724 - accuracy: 0.9722 - val_loss: 0.1255 - val_accuracy: 1.0000\n",
      "Epoch 208/240\n",
      "108/108 [==============================] - 0s 538us/sample - loss: 0.1712 - accuracy: 0.9722 - val_loss: 0.1221 - val_accuracy: 1.0000\n",
      "Epoch 209/240\n",
      "108/108 [==============================] - 0s 547us/sample - loss: 0.1708 - accuracy: 0.9722 - val_loss: 0.1199 - val_accuracy: 1.0000\n",
      "Epoch 210/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.1698 - accuracy: 0.9722 - val_loss: 0.1182 - val_accuracy: 1.0000\n",
      "Epoch 211/240\n",
      "108/108 [==============================] - 0s 621us/sample - loss: 0.1693 - accuracy: 0.9815 - val_loss: 0.1251 - val_accuracy: 1.0000\n",
      "Epoch 212/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.1681 - accuracy: 0.9722 - val_loss: 0.1255 - val_accuracy: 1.0000\n",
      "Epoch 213/240\n",
      "108/108 [==============================] - 0s 593us/sample - loss: 0.1669 - accuracy: 0.9722 - val_loss: 0.1299 - val_accuracy: 1.0000\n",
      "Epoch 214/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.1682 - accuracy: 0.9815 - val_loss: 0.1272 - val_accuracy: 1.0000\n",
      "Epoch 215/240\n",
      "108/108 [==============================] - 0s 593us/sample - loss: 0.1650 - accuracy: 0.9630 - val_loss: 0.1235 - val_accuracy: 1.0000\n",
      "Epoch 216/240\n",
      "108/108 [==============================] - 0s 538us/sample - loss: 0.1636 - accuracy: 0.9722 - val_loss: 0.1152 - val_accuracy: 1.0000\n",
      "Epoch 217/240\n",
      "108/108 [==============================] - 0s 556us/sample - loss: 0.1650 - accuracy: 0.9722 - val_loss: 0.1130 - val_accuracy: 1.0000\n",
      "Epoch 218/240\n",
      "108/108 [==============================] - 0s 612us/sample - loss: 0.1623 - accuracy: 0.9815 - val_loss: 0.1108 - val_accuracy: 1.0000\n",
      "Epoch 219/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.1606 - accuracy: 0.9815 - val_loss: 0.1200 - val_accuracy: 1.0000\n",
      "Epoch 220/240\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.1598 - accuracy: 0.9722 - val_loss: 0.1090 - val_accuracy: 1.0000\n",
      "Epoch 221/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 0s 575us/sample - loss: 0.1604 - accuracy: 0.9815 - val_loss: 0.1079 - val_accuracy: 1.0000\n",
      "Epoch 222/240\n",
      "108/108 [==============================] - 0s 538us/sample - loss: 0.1584 - accuracy: 0.9722 - val_loss: 0.0996 - val_accuracy: 1.0000\n",
      "Epoch 223/240\n",
      "108/108 [==============================] - 0s 538us/sample - loss: 0.1577 - accuracy: 0.9815 - val_loss: 0.1045 - val_accuracy: 1.0000\n",
      "Epoch 224/240\n",
      "108/108 [==============================] - 0s 528us/sample - loss: 0.1591 - accuracy: 0.9722 - val_loss: 0.1021 - val_accuracy: 1.0000\n",
      "Epoch 225/240\n",
      "108/108 [==============================] - 0s 547us/sample - loss: 0.1553 - accuracy: 0.9815 - val_loss: 0.1027 - val_accuracy: 1.0000\n",
      "Epoch 226/240\n",
      "108/108 [==============================] - 0s 584us/sample - loss: 0.1557 - accuracy: 0.9722 - val_loss: 0.0973 - val_accuracy: 1.0000\n",
      "Epoch 227/240\n",
      "108/108 [==============================] - 0s 612us/sample - loss: 0.1544 - accuracy: 0.9815 - val_loss: 0.1012 - val_accuracy: 1.0000\n",
      "Epoch 228/240\n",
      "108/108 [==============================] - 0s 584us/sample - loss: 0.1537 - accuracy: 0.9815 - val_loss: 0.0970 - val_accuracy: 1.0000\n",
      "Epoch 229/240\n",
      "108/108 [==============================] - 0s 584us/sample - loss: 0.1537 - accuracy: 0.9815 - val_loss: 0.1061 - val_accuracy: 1.0000\n",
      "Epoch 230/240\n",
      "108/108 [==============================] - 0s 538us/sample - loss: 0.1510 - accuracy: 0.9722 - val_loss: 0.1051 - val_accuracy: 1.0000\n",
      "Epoch 231/240\n",
      "108/108 [==============================] - 0s 584us/sample - loss: 0.1505 - accuracy: 0.9722 - val_loss: 0.0999 - val_accuracy: 1.0000\n",
      "Epoch 232/240\n",
      "108/108 [==============================] - 0s 538us/sample - loss: 0.1498 - accuracy: 0.9815 - val_loss: 0.1032 - val_accuracy: 1.0000\n",
      "Epoch 233/240\n",
      "108/108 [==============================] - 0s 538us/sample - loss: 0.1488 - accuracy: 0.9722 - val_loss: 0.1014 - val_accuracy: 1.0000\n",
      "Epoch 234/240\n",
      "108/108 [==============================] - 0s 593us/sample - loss: 0.1481 - accuracy: 0.9722 - val_loss: 0.1068 - val_accuracy: 1.0000\n",
      "Epoch 235/240\n",
      "108/108 [==============================] - 0s 565us/sample - loss: 0.1482 - accuracy: 0.9722 - val_loss: 0.0976 - val_accuracy: 1.0000\n",
      "Epoch 236/240\n",
      "108/108 [==============================] - 0s 593us/sample - loss: 0.1471 - accuracy: 0.9722 - val_loss: 0.0913 - val_accuracy: 1.0000\n",
      "Epoch 237/240\n",
      "108/108 [==============================] - 0s 593us/sample - loss: 0.1474 - accuracy: 0.9722 - val_loss: 0.0879 - val_accuracy: 1.0000\n",
      "Epoch 238/240\n",
      "108/108 [==============================] - 0s 538us/sample - loss: 0.1454 - accuracy: 0.9815 - val_loss: 0.0924 - val_accuracy: 1.0000\n",
      "Epoch 239/240\n",
      "108/108 [==============================] - 0s 556us/sample - loss: 0.1452 - accuracy: 0.9815 - val_loss: 0.1011 - val_accuracy: 1.0000\n",
      "Epoch 240/240\n",
      "108/108 [==============================] - 0s 547us/sample - loss: 0.1447 - accuracy: 0.9722 - val_loss: 0.0920 - val_accuracy: 1.0000\n",
      "30/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 133us/sample - loss: 0.1974 - accuracy: 0.9667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.19740884006023407, 0.96666664]"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, train_labels,\n",
    "          epochs = 240,\n",
    "         validation_split = .1,\n",
    "         shuffle = True)\n",
    "results = model.evaluate(test_data, test_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 6 : Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25523937, 0.3581103 , 0.38665035],\n",
       "       [0.22296008, 0.35367966, 0.4233602 ],\n",
       "       [0.16228591, 0.36731878, 0.4703954 ],\n",
       "       [0.1537067 , 0.37935847, 0.46693474],\n",
       "       [0.23673543, 0.35523972, 0.40802488],\n",
       "       [0.1059728 , 0.34904134, 0.5449859 ],\n",
       "       [0.23050348, 0.349751  , 0.41974553],\n",
       "       [0.16621238, 0.36341423, 0.47037345],\n",
       "       [0.3051679 , 0.3422039 , 0.35262823],\n",
       "       [0.27818742, 0.34164086, 0.38017175],\n",
       "       [0.13612896, 0.36072615, 0.5031449 ],\n",
       "       [0.29609665, 0.33345813, 0.37044516],\n",
       "       [0.17732385, 0.37453288, 0.44814324],\n",
       "       [0.5024606 , 0.22963558, 0.2679038 ],\n",
       "       [0.22982663, 0.3519563 , 0.41821712],\n",
       "       [0.18453017, 0.3498933 , 0.46557647],\n",
       "       [0.14760967, 0.34132499, 0.51106536],\n",
       "       [0.21208848, 0.34046638, 0.4474452 ],\n",
       "       [0.21299592, 0.36840248, 0.41860166],\n",
       "       [0.24252175, 0.33507794, 0.4224004 ],\n",
       "       [0.20247099, 0.37084803, 0.4266809 ],\n",
       "       [0.5207796 , 0.22106525, 0.25815514],\n",
       "       [0.1824099 , 0.356139  , 0.46145114],\n",
       "       [0.52322817, 0.21293186, 0.26384002],\n",
       "       [0.5515838 , 0.2169033 , 0.23151293],\n",
       "       [0.25465435, 0.34580138, 0.39954427],\n",
       "       [0.23567337, 0.34216446, 0.42216218],\n",
       "       [0.49649554, 0.23541151, 0.26809296],\n",
       "       [0.2711217 , 0.32833898, 0.40053928],\n",
       "       [0.465729  , 0.2563463 , 0.27792475]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [12, 13, 14, 15]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.arange(16).reshape(4,4)).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
