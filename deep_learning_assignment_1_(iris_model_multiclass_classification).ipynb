{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSIGNMENT : IRIS MULTI-CLASS CLASSIFICATION\n",
    "\n",
    "###### Purpose :\n",
    "To predict the species of flower .\n",
    "###### Description :\n",
    "The dataset contains a set of 150 records under 5 attributes - Petal Length, Petal Width, Sepal Length, Sepal width and Class(Species).\n",
    "###### Requirements :\n",
    "1) Code must be in tf 2.0 .\n",
    "\n",
    "2) Accuracy must be in between 95-97% .\n",
    "\n",
    "3) Model shouldn't be Overfit (You can add drop out layer for this) ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1 : Load all the necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import models, layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2 : Data Preparation\n",
    "This step consists of multiple sub steps from data loading [download](https://github.com/ramsha275/PIAIC-Sir-Anees-Quarter-2/blob/master/Deep%20Learning/iris.csv),shuffling ,spliting in **Train** and **Test** sets to one-hot-enconding on labels . \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal.length  sepal.width  petal.length  petal.width    variety\n",
       "0             5.1          3.5           1.4          0.2     Setosa\n",
       "1             4.9          3.0           1.4          0.2     Setosa\n",
       "2             4.7          3.2           1.3          0.2     Setosa\n",
       "3             4.6          3.1           1.5          0.2     Setosa\n",
       "4             5.0          3.6           1.4          0.2     Setosa\n",
       "..            ...          ...           ...          ...        ...\n",
       "145           6.7          3.0           5.2          2.3  Virginica\n",
       "146           6.3          2.5           5.0          1.9  Virginica\n",
       "147           6.5          3.0           5.2          2.0  Virginica\n",
       "148           6.2          3.4           5.4          2.3  Virginica\n",
       "149           5.9          3.0           5.1          1.8  Virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('iris.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.asarray(data.iloc[:,:-1])\n",
    "y_data = np.asarray(data.iloc[:,-1])\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "one_hot = LabelBinarizer()\n",
    "y_data = one_hot.fit_transform(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(x_data, y_data,\n",
    "                                                                    test_size=0.2,\n",
    "                                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 3)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3 : Model Architecture \n",
    "\n",
    "\n",
    "###### Input : 4 \n",
    "###### 1 hidden Layer : 8 nodes\n",
    "###### Output : 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(8, activation = 'tanh', input_shape = (train_data.shape[1],)))\n",
    "model.add(layers.Dense(3, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 4 : Compilation Step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 5 : Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 108 samples, validate on 12 samples\n",
      "Epoch 1/100\n",
      "108/108 [==============================] - 2s 14ms/sample - loss: 1.3796 - accuracy: 0.0000e+00 - val_loss: 1.3171 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "108/108 [==============================] - 0s 825us/sample - loss: 1.3303 - accuracy: 0.0000e+00 - val_loss: 1.2817 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "108/108 [==============================] - 0s 751us/sample - loss: 1.2955 - accuracy: 0.0000e+00 - val_loss: 1.2502 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 1.2648 - accuracy: 0.0000e+00 - val_loss: 1.2249 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "108/108 [==============================] - 0s 612us/sample - loss: 1.2404 - accuracy: 0.0000e+00 - val_loss: 1.2012 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "108/108 [==============================] - 0s 593us/sample - loss: 1.2178 - accuracy: 0.0000e+00 - val_loss: 1.1818 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "108/108 [==============================] - 0s 732us/sample - loss: 1.1982 - accuracy: 0.0000e+00 - val_loss: 1.1634 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "108/108 [==============================] - 0s 612us/sample - loss: 1.1797 - accuracy: 0.0093 - val_loss: 1.1455 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "108/108 [==============================] - 0s 612us/sample - loss: 1.1626 - accuracy: 0.0648 - val_loss: 1.1339 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 1.1493 - accuracy: 0.1111 - val_loss: 1.1204 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "108/108 [==============================] - 0s 732us/sample - loss: 1.1361 - accuracy: 0.2130 - val_loss: 1.1088 - val_accuracy: 0.2500\n",
      "Epoch 12/100\n",
      "108/108 [==============================] - 0s 760us/sample - loss: 1.1235 - accuracy: 0.3056 - val_loss: 1.0990 - val_accuracy: 0.3333\n",
      "Epoch 13/100\n",
      "108/108 [==============================] - 0s 667us/sample - loss: 1.1134 - accuracy: 0.3519 - val_loss: 1.0904 - val_accuracy: 0.3333\n",
      "Epoch 14/100\n",
      "108/108 [==============================] - 0s 732us/sample - loss: 1.1039 - accuracy: 0.3704 - val_loss: 1.0817 - val_accuracy: 0.3333\n",
      "Epoch 15/100\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 1.0943 - accuracy: 0.3704 - val_loss: 1.0737 - val_accuracy: 0.3333\n",
      "Epoch 16/100\n",
      "108/108 [==============================] - 0s 612us/sample - loss: 1.0846 - accuracy: 0.3611 - val_loss: 1.0669 - val_accuracy: 0.3333\n",
      "Epoch 17/100\n",
      "108/108 [==============================] - 0s 732us/sample - loss: 1.0772 - accuracy: 0.3704 - val_loss: 1.0607 - val_accuracy: 0.4167\n",
      "Epoch 18/100\n",
      "108/108 [==============================] - 0s 612us/sample - loss: 1.0712 - accuracy: 0.3704 - val_loss: 1.0539 - val_accuracy: 0.3333\n",
      "Epoch 19/100\n",
      "108/108 [==============================] - 0s 612us/sample - loss: 1.0620 - accuracy: 0.3704 - val_loss: 1.0488 - val_accuracy: 0.4167\n",
      "Epoch 20/100\n",
      "108/108 [==============================] - 0s 732us/sample - loss: 1.0540 - accuracy: 0.3704 - val_loss: 1.0421 - val_accuracy: 0.4167\n",
      "Epoch 21/100\n",
      "108/108 [==============================] - 0s 621us/sample - loss: 1.0467 - accuracy: 0.3704 - val_loss: 1.0362 - val_accuracy: 0.4167\n",
      "Epoch 22/100\n",
      "108/108 [==============================] - 0s 741us/sample - loss: 1.0400 - accuracy: 0.3796 - val_loss: 1.0286 - val_accuracy: 0.4167\n",
      "Epoch 23/100\n",
      "108/108 [==============================] - 0s 723us/sample - loss: 1.0329 - accuracy: 0.3796 - val_loss: 1.0215 - val_accuracy: 0.3333\n",
      "Epoch 24/100\n",
      "108/108 [==============================] - 0s 714us/sample - loss: 1.0256 - accuracy: 0.3704 - val_loss: 1.0164 - val_accuracy: 0.4167\n",
      "Epoch 25/100\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 1.0184 - accuracy: 0.3796 - val_loss: 1.0100 - val_accuracy: 0.4167\n",
      "Epoch 26/100\n",
      "108/108 [==============================] - 0s 658us/sample - loss: 1.0120 - accuracy: 0.3796 - val_loss: 1.0023 - val_accuracy: 0.4167\n",
      "Epoch 27/100\n",
      "108/108 [==============================] - 0s 732us/sample - loss: 1.0057 - accuracy: 0.3704 - val_loss: 0.9946 - val_accuracy: 0.4167\n",
      "Epoch 28/100\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.9988 - accuracy: 0.3796 - val_loss: 0.9877 - val_accuracy: 0.4167\n",
      "Epoch 29/100\n",
      "108/108 [==============================] - 0s 612us/sample - loss: 0.9895 - accuracy: 0.3704 - val_loss: 0.9806 - val_accuracy: 0.4167\n",
      "Epoch 30/100\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.9855 - accuracy: 0.3704 - val_loss: 0.9731 - val_accuracy: 0.4167\n",
      "Epoch 31/100\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.9760 - accuracy: 0.3796 - val_loss: 0.9648 - val_accuracy: 0.4167\n",
      "Epoch 32/100\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.9678 - accuracy: 0.3704 - val_loss: 0.9571 - val_accuracy: 0.4167\n",
      "Epoch 33/100\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.9610 - accuracy: 0.3889 - val_loss: 0.9501 - val_accuracy: 0.4167\n",
      "Epoch 34/100\n",
      "108/108 [==============================] - 0s 621us/sample - loss: 0.9537 - accuracy: 0.3704 - val_loss: 0.9443 - val_accuracy: 0.4167\n",
      "Epoch 35/100\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.9466 - accuracy: 0.4352 - val_loss: 0.9358 - val_accuracy: 0.4167\n",
      "Epoch 36/100\n",
      "108/108 [==============================] - 0s 630us/sample - loss: 0.9410 - accuracy: 0.3796 - val_loss: 0.9293 - val_accuracy: 0.4167\n",
      "Epoch 37/100\n",
      "108/108 [==============================] - 0s 677us/sample - loss: 0.9328 - accuracy: 0.3889 - val_loss: 0.9209 - val_accuracy: 0.4167\n",
      "Epoch 38/100\n",
      "108/108 [==============================] - 0s 741us/sample - loss: 0.9243 - accuracy: 0.3889 - val_loss: 0.9142 - val_accuracy: 0.4167\n",
      "Epoch 39/100\n",
      "108/108 [==============================] - 0s 778us/sample - loss: 0.9173 - accuracy: 0.3981 - val_loss: 0.9070 - val_accuracy: 0.4167\n",
      "Epoch 40/100\n",
      "108/108 [==============================] - 0s 686us/sample - loss: 0.9093 - accuracy: 0.4352 - val_loss: 0.8996 - val_accuracy: 0.4167\n",
      "Epoch 41/100\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.9014 - accuracy: 0.5000 - val_loss: 0.8889 - val_accuracy: 0.4167\n",
      "Epoch 42/100\n",
      "108/108 [==============================] - 0s 593us/sample - loss: 0.8930 - accuracy: 0.4352 - val_loss: 0.8810 - val_accuracy: 0.4167\n",
      "Epoch 43/100\n",
      "108/108 [==============================] - 0s 621us/sample - loss: 0.8846 - accuracy: 0.5185 - val_loss: 0.8703 - val_accuracy: 0.4167\n",
      "Epoch 44/100\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.8783 - accuracy: 0.5000 - val_loss: 0.8621 - val_accuracy: 0.4167\n",
      "Epoch 45/100\n",
      "108/108 [==============================] - 0s 686us/sample - loss: 0.8687 - accuracy: 0.5370 - val_loss: 0.8524 - val_accuracy: 0.4167\n",
      "Epoch 46/100\n",
      "108/108 [==============================] - 0s 732us/sample - loss: 0.8598 - accuracy: 0.5278 - val_loss: 0.8432 - val_accuracy: 0.5833\n",
      "Epoch 47/100\n",
      "108/108 [==============================] - 0s 751us/sample - loss: 0.8520 - accuracy: 0.6759 - val_loss: 0.8340 - val_accuracy: 0.5833\n",
      "Epoch 48/100\n",
      "108/108 [==============================] - 0s 723us/sample - loss: 0.8443 - accuracy: 0.6852 - val_loss: 0.8229 - val_accuracy: 0.5833\n",
      "Epoch 49/100\n",
      "108/108 [==============================] - 0s 575us/sample - loss: 0.8338 - accuracy: 0.6204 - val_loss: 0.8130 - val_accuracy: 0.6667\n",
      "Epoch 50/100\n",
      "108/108 [==============================] - 0s 621us/sample - loss: 0.8254 - accuracy: 0.6852 - val_loss: 0.8036 - val_accuracy: 0.6667\n",
      "Epoch 51/100\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.8190 - accuracy: 0.7407 - val_loss: 0.7941 - val_accuracy: 0.7500\n",
      "Epoch 52/100\n",
      "108/108 [==============================] - 0s 927us/sample - loss: 0.8124 - accuracy: 0.6574 - val_loss: 0.7863 - val_accuracy: 0.7500\n",
      "Epoch 53/100\n",
      "108/108 [==============================] - 0s 2ms/sample - loss: 0.8020 - accuracy: 0.6667 - val_loss: 0.7781 - val_accuracy: 0.9167\n",
      "Epoch 54/100\n",
      "108/108 [==============================] - 0s 1ms/sample - loss: 0.7962 - accuracy: 0.7222 - val_loss: 0.7700 - val_accuracy: 0.9167\n",
      "Epoch 55/100\n",
      "108/108 [==============================] - 0s 1ms/sample - loss: 0.7871 - accuracy: 0.8148 - val_loss: 0.7593 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "108/108 [==============================] - 0s 843us/sample - loss: 0.7804 - accuracy: 0.7037 - val_loss: 0.7509 - val_accuracy: 0.7500\n",
      "Epoch 57/100\n",
      "108/108 [==============================] - 0s 1ms/sample - loss: 0.7741 - accuracy: 0.6944 - val_loss: 0.7426 - val_accuracy: 0.7500\n",
      "Epoch 58/100\n",
      "108/108 [==============================] - 0s 880us/sample - loss: 0.7679 - accuracy: 0.7130 - val_loss: 0.7356 - val_accuracy: 0.8333\n",
      "Epoch 59/100\n",
      "108/108 [==============================] - 0s 649us/sample - loss: 0.7609 - accuracy: 0.7778 - val_loss: 0.7293 - val_accuracy: 0.9167\n",
      "Epoch 60/100\n",
      "108/108 [==============================] - 0s 714us/sample - loss: 0.7534 - accuracy: 0.7778 - val_loss: 0.7201 - val_accuracy: 0.9167\n",
      "Epoch 61/100\n",
      "108/108 [==============================] - 0s 538us/sample - loss: 0.7478 - accuracy: 0.8056 - val_loss: 0.7118 - val_accuracy: 0.9167\n",
      "Epoch 62/100\n",
      "108/108 [==============================] - 0s 677us/sample - loss: 0.7382 - accuracy: 0.7685 - val_loss: 0.7035 - val_accuracy: 0.9167\n",
      "Epoch 63/100\n",
      "108/108 [==============================] - 0s 575us/sample - loss: 0.7346 - accuracy: 0.7500 - val_loss: 0.6964 - val_accuracy: 0.7500\n",
      "Epoch 64/100\n",
      "108/108 [==============================] - 0s 843us/sample - loss: 0.7264 - accuracy: 0.6852 - val_loss: 0.6898 - val_accuracy: 0.9167\n",
      "Epoch 65/100\n",
      "108/108 [==============================] - 0s 1ms/sample - loss: 0.7192 - accuracy: 0.8333 - val_loss: 0.6827 - val_accuracy: 0.9167\n",
      "Epoch 66/100\n",
      "108/108 [==============================] - 0s 593us/sample - loss: 0.7129 - accuracy: 0.7778 - val_loss: 0.6757 - val_accuracy: 0.9167\n",
      "Epoch 67/100\n",
      "108/108 [==============================] - 0s 556us/sample - loss: 0.7066 - accuracy: 0.7593 - val_loss: 0.6674 - val_accuracy: 0.9167\n",
      "Epoch 68/100\n",
      "108/108 [==============================] - 0s 547us/sample - loss: 0.7009 - accuracy: 0.8241 - val_loss: 0.6611 - val_accuracy: 0.9167\n",
      "Epoch 69/100\n",
      "108/108 [==============================] - 0s 528us/sample - loss: 0.6926 - accuracy: 0.8056 - val_loss: 0.6528 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "108/108 [==============================] - 0s 584us/sample - loss: 0.6896 - accuracy: 0.8333 - val_loss: 0.6448 - val_accuracy: 0.9167\n",
      "Epoch 71/100\n",
      "108/108 [==============================] - 0s 565us/sample - loss: 0.6802 - accuracy: 0.8241 - val_loss: 0.6377 - val_accuracy: 0.9167\n",
      "Epoch 72/100\n",
      "108/108 [==============================] - 0s 612us/sample - loss: 0.6755 - accuracy: 0.8333 - val_loss: 0.6308 - val_accuracy: 0.9167\n",
      "Epoch 73/100\n",
      "108/108 [==============================] - 0s 639us/sample - loss: 0.6666 - accuracy: 0.8519 - val_loss: 0.6226 - val_accuracy: 0.9167\n",
      "Epoch 74/100\n",
      "108/108 [==============================] - 0s 927us/sample - loss: 0.6599 - accuracy: 0.8519 - val_loss: 0.6144 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "108/108 [==============================] - 0s 1ms/sample - loss: 0.6548 - accuracy: 0.8796 - val_loss: 0.6070 - val_accuracy: 0.9167\n",
      "Epoch 76/100\n",
      "108/108 [==============================] - 0s 899us/sample - loss: 0.6498 - accuracy: 0.8796 - val_loss: 0.5999 - val_accuracy: 0.9167\n",
      "Epoch 77/100\n",
      "108/108 [==============================] - 0s 992us/sample - loss: 0.6451 - accuracy: 0.8611 - val_loss: 0.5941 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "108/108 [==============================] - 0s 945us/sample - loss: 0.6343 - accuracy: 0.9074 - val_loss: 0.5879 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "108/108 [==============================] - 0s 732us/sample - loss: 0.6294 - accuracy: 0.8889 - val_loss: 0.5816 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "108/108 [==============================] - 0s 686us/sample - loss: 0.6233 - accuracy: 0.9167 - val_loss: 0.5729 - val_accuracy: 0.9167\n",
      "Epoch 81/100\n",
      "108/108 [==============================] - 0s 602us/sample - loss: 0.6173 - accuracy: 0.8796 - val_loss: 0.5670 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "108/108 [==============================] - 0s 704us/sample - loss: 0.6108 - accuracy: 0.8981 - val_loss: 0.5609 - val_accuracy: 0.9167\n",
      "Epoch 83/100\n",
      "108/108 [==============================] - 0s 751us/sample - loss: 0.6064 - accuracy: 0.8519 - val_loss: 0.5538 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "108/108 [==============================] - 0s 612us/sample - loss: 0.5989 - accuracy: 0.8889 - val_loss: 0.5481 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "108/108 [==============================] - 0s 593us/sample - loss: 0.5952 - accuracy: 0.9167 - val_loss: 0.5407 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "108/108 [==============================] - 0s 621us/sample - loss: 0.5874 - accuracy: 0.9352 - val_loss: 0.5332 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "108/108 [==============================] - 0s 677us/sample - loss: 0.5822 - accuracy: 0.9352 - val_loss: 0.5274 - val_accuracy: 0.9167\n",
      "Epoch 88/100\n",
      "108/108 [==============================] - 0s 704us/sample - loss: 0.5780 - accuracy: 0.8611 - val_loss: 0.5202 - val_accuracy: 0.9167\n",
      "Epoch 89/100\n",
      "108/108 [==============================] - 0s 658us/sample - loss: 0.5729 - accuracy: 0.9074 - val_loss: 0.5150 - val_accuracy: 0.9167\n",
      "Epoch 90/100\n",
      "108/108 [==============================] - 0s 973us/sample - loss: 0.5677 - accuracy: 0.9167 - val_loss: 0.5095 - val_accuracy: 0.9167\n",
      "Epoch 91/100\n",
      "108/108 [==============================] - 0s 1ms/sample - loss: 0.5629 - accuracy: 0.9074 - val_loss: 0.5043 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "108/108 [==============================] - 0s 917us/sample - loss: 0.5569 - accuracy: 0.9352 - val_loss: 0.4995 - val_accuracy: 0.9167\n",
      "Epoch 93/100\n",
      "108/108 [==============================] - 0s 584us/sample - loss: 0.5521 - accuracy: 0.9167 - val_loss: 0.4930 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "108/108 [==============================] - 0s 677us/sample - loss: 0.5492 - accuracy: 0.9352 - val_loss: 0.4889 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "108/108 [==============================] - 0s 704us/sample - loss: 0.5439 - accuracy: 0.9259 - val_loss: 0.4840 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "108/108 [==============================] - 0s 769us/sample - loss: 0.5393 - accuracy: 0.9444 - val_loss: 0.4784 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "108/108 [==============================] - 0s 732us/sample - loss: 0.5351 - accuracy: 0.9444 - val_loss: 0.4735 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "108/108 [==============================] - 0s 621us/sample - loss: 0.5308 - accuracy: 0.9352 - val_loss: 0.4698 - val_accuracy: 0.9167\n",
      "Epoch 99/100\n",
      "108/108 [==============================] - 0s 658us/sample - loss: 0.5286 - accuracy: 0.9352 - val_loss: 0.4644 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "108/108 [==============================] - 0s 714us/sample - loss: 0.5232 - accuracy: 0.9259 - val_loss: 0.4602 - val_accuracy: 0.9167\n",
      "30/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 100us/sample - loss: 0.3936 - accuracy: 0.9667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.39356228709220886, 0.96666664]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, train_labels,\n",
    "          epochs = 100,\n",
    "         validation_split = .1)\n",
    "results = model.evaluate(test_data, test_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 6 : Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.85257787, 0.12676811, 0.02065398],\n",
       "       [0.16929357, 0.43432534, 0.39638114],\n",
       "       [0.8403691 , 0.13391799, 0.02571298],\n",
       "       [0.82099277, 0.15316363, 0.02584358],\n",
       "       [0.06273608, 0.30490413, 0.6323598 ],\n",
       "       [0.8552069 , 0.1226514 , 0.02214173],\n",
       "       [0.1093288 , 0.5104832 , 0.38018805],\n",
       "       [0.14789484, 0.49163485, 0.36047035],\n",
       "       [0.8482704 , 0.12985446, 0.02187516],\n",
       "       [0.7958685 , 0.17121057, 0.03292092],\n",
       "       [0.08681767, 0.33343318, 0.57974917],\n",
       "       [0.8227553 , 0.15011239, 0.02713232],\n",
       "       [0.07193739, 0.33205116, 0.5960115 ],\n",
       "       [0.04397451, 0.37883592, 0.57718956],\n",
       "       [0.05423792, 0.34302726, 0.60273486],\n",
       "       [0.7305357 , 0.22840925, 0.04105507],\n",
       "       [0.805657  , 0.1627145 , 0.03162848],\n",
       "       [0.84865284, 0.12693687, 0.02441035],\n",
       "       [0.07971966, 0.37580177, 0.54447854],\n",
       "       [0.11665489, 0.4539599 , 0.42938516],\n",
       "       [0.11641696, 0.43272105, 0.45086196],\n",
       "       [0.89455336, 0.0900517 , 0.01539497],\n",
       "       [0.9055984 , 0.07974569, 0.01465582],\n",
       "       [0.10405938, 0.34901348, 0.54692715],\n",
       "       [0.8597487 , 0.1165565 , 0.02369478],\n",
       "       [0.02246685, 0.26769662, 0.70983654],\n",
       "       [0.8701537 , 0.10991673, 0.01992963],\n",
       "       [0.8811915 , 0.10134806, 0.0174605 ],\n",
       "       [0.15475392, 0.54325414, 0.30199194],\n",
       "       [0.11943822, 0.5349823 , 0.34557953]], dtype=float32)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
